syntax = "proto3";

option go_package = "github.com/Max-Gabriel-Susman/delphi-training-service/training";

// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc TrainModel (TrainModelRequest) returns (TrainModelReply) {}
  /// Decode token for a list of prefilled batches
  rpc Decode (DecodeRequest) returns (DecodeResponse);
}

// The request message containing the user's name.
message TrainModelRequest {
  string name = 1;
}

// The response message containing the greetings
message TrainModelReply {
  string message = 1;
}

message PrefillTokens {
  /// Prefill Token IDs
  repeated uint32 ids = 1;
  /// Prefill Logprobs
  repeated float logprobs = 2;
  /// Prefill tokens
  repeated string texts = 3;
}

message CachedBatch {
  /// Batch ID
  uint64 id = 1;
  /// Individual requests ids
  repeated uint64 request_ids = 2;
  /// Batch size (==len(requests))
  uint32 size = 3;
  /// Maximum number of tokens this batch will grow to
  uint32 max_tokens = 4;
}

enum FinishReason {
  FINISH_REASON_LENGTH = 0;
  FINISH_REASON_EOS_TOKEN = 1;
  FINISH_REASON_STOP_SEQUENCE = 2;
}

message GeneratedText {
  /// Output
  string text = 1;
  /// Number of generated tokens
  uint32 generated_tokens = 2;
  /// Finish reason
  FinishReason finish_reason = 3;
  /// Seed
  optional uint64 seed = 4;
}

message Generation {
    /// Request ID
    uint64 request_id = 1;
    /// Prefill tokens (optional)
    PrefillTokens prefill_tokens = 2;
    /// Token ID
    uint32 token_id = 3;
    /// Logprob
    float token_logprob = 4;
    /// Text
    string token_text = 5;
    /// Is it a special token
    bool token_is_special = 6;
    /// Complete generated text
    optional GeneratedText generated_text = 7;
}

message DecodeRequest {
    /// Cached batches
    repeated CachedBatch batches = 1;
}

message DecodeResponse {
    /// Decodes
    repeated Generation generations = 1;
    /// Next batch (cached)
    optional CachedBatch batch = 2;
}